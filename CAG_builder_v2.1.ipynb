{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybGy3TXnOibF",
    "outputId": "37d9390f-3d97-4ea5-f95a-2fe6d45d56bc"
   },
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install torch_geometric\n",
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZKlyiXQNPEld"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "import typing as tp\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.classes.digraph import DiGraph\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "qyCKZywxlyki"
   },
   "outputs": [],
   "source": [
    "# Building graph\n",
    "def dfs_build_graph(root_node:ET.Element) -> tp.Tuple[DiGraph, tp.List, str]:\n",
    "    graph = nx.DiGraph() \n",
    "\n",
    "    leafs = []\n",
    "    root_name = 0\n",
    "    suf = iter(range(10_000_000))\n",
    "\n",
    "    def dfs(vertice:ET.Element) -> str:\n",
    "        # Extract node name in AST\n",
    "\n",
    "        tag = vertice.tag # XML tag like <SimpleName>\n",
    "\n",
    "        node = next(suf)\n",
    "        node_name = tag   \n",
    "\n",
    "        graph.add_node(node, text=[node_name])\n",
    "#         graph.add_node(node, text=node_name)\n",
    "        \n",
    "        # Recursively traverse the child nodes\n",
    "        for child in vertice:\n",
    "            child_node = dfs(child)\n",
    "            graph.add_edge(child_node, node)\n",
    "          \n",
    "        if len(vertice) == 0:\n",
    "            leaf_node = next(suf)\n",
    "            leaf_name = vertice.text.strip()\n",
    "\n",
    "            graph.add_node(leaf_node, text=[leaf_name])\n",
    "#             graph.add_node(leaf_node, text=leaf_name)\n",
    "            graph.add_edge(leaf_node, node)\n",
    "\n",
    "            leafs.append(leaf_node)\n",
    "            \n",
    "        return node\n",
    "\n",
    "    # TODO: add sink and leafs edges here, not outside\n",
    "    \n",
    "    dfs(root_node)\n",
    "\n",
    "    return (graph, leafs, root_name)\n",
    "\n",
    "# Merging Single-Entry Node Sequences\n",
    "def dfs_merge_sequences(graph, node: str):\n",
    "  # node: str, key of node in graph.nodes\n",
    "\n",
    "  nodes_one_succ = []\n",
    "\n",
    "  while(graph.in_degree(node) == 1):\n",
    "      nodes_one_succ.append(node)\n",
    "      node = list(graph.predecessors(node))[0]\n",
    "\n",
    "  # leaf nodes sholdn't be merged, so in_degree != 0\n",
    "\n",
    "  if len(nodes_one_succ) > 1:\n",
    "      parent = nodes_one_succ[0]\n",
    "\n",
    "      for child in nodes_one_succ[1:]:\n",
    "          nx.contracted_nodes(graph, parent, child, self_loops=False, copy=False)\n",
    "\n",
    "      # concatenate tokens of merged vertices\n",
    "      p = graph.nodes(data=True)[parent]\n",
    "        \n",
    "      p['text'] = p['text'] + [args['text'][0] for args in p['contraction'].values()]\n",
    "#       p['text'] += ',' + ','.join(args['text'] for args in p['contraction'].values()) # TODO\n",
    "\n",
    "      del p['contraction']\n",
    "\n",
    "  # now node is either a leaf or has degree >= 2\n",
    "\n",
    "  for child in graph.predecessors(node):\n",
    "      dfs_merge_sequences(graph, child)\n",
    "\n",
    "# Merging Aggregation Structures\n",
    "# TODO: merge only vertices with specific AST node names\n",
    "def dfs_merge_aggregations(graph, node: str):\n",
    "\n",
    "    # Recursively traverse the child nodes\n",
    "    children_degs = [graph.in_degree(child) for child in graph.predecessors(node)]\n",
    "    \n",
    "    if not children_degs:\n",
    "        # node is a leaf\n",
    "        return\n",
    "\n",
    "    if len(children_degs) >= 2 and max(children_degs) <= 1: # TODO\n",
    "        # all children are either have deg=1 or a leaf\n",
    "        # merging node and children\n",
    "        children = list(graph.predecessors(node))\n",
    "        \n",
    "        for child in (children):\n",
    "            nx.contracted_nodes(graph, node, child, self_loops=False, copy=False)\n",
    "        \n",
    "        parent = graph.nodes(data=True)[node]\n",
    "        parent['text'] = [args['text'] for args in parent['contraction'].values()] + [parent['text']]\n",
    "#         parent['text'] += '|' + \\\n",
    "#             '|'.join([args['text'] for args in parent['contraction'].values()]) # TODO\n",
    "        del parent['contraction']\n",
    "\n",
    "    for child in graph.predecessors(node):\n",
    "        dfs_merge_aggregations(graph, child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "qZGKD_SiFxNM"
   },
   "outputs": [],
   "source": [
    "def build_graph(root_node:ET.Element) -> DiGraph:\n",
    "    \n",
    "    graph, leafs, root_name = dfs_build_graph(root_node)\n",
    "\n",
    "    dfs_merge_sequences(graph, root_name)\n",
    "    dfs_merge_aggregations(graph, root_name)\n",
    "\n",
    "    # Adding edges between leafs (consequent initial code tokens)\n",
    "    for u, v in zip(leafs[:-1], leafs[1:]):\n",
    "        graph.add_edge(u, v)\n",
    "\n",
    "    # Adding ROOT node - global graph's sink\n",
    "    for v in graph.nodes:\n",
    "        if v != root_name:\n",
    "            graph.add_edge(v, root_name)\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "4mRxMTwyEyTQ"
   },
   "outputs": [],
   "source": [
    "def graph_to_data(graph:DiGraph, target:int) -> Data:\n",
    "    graph = nx.convert_node_labels_to_integers(graph)\n",
    "    return Data(edge_index=torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous().view(2, -1),\n",
    "                edge_attr=None,\n",
    "                x=list(nx.get_node_attributes(graph, 'text').values()),\n",
    "                y=target\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_words(method, threshold=1e6):\n",
    "    words = 0\n",
    "    if not method.findall('.Block'):\n",
    "        return 0\n",
    "    for elem in method.findall('.Block')[0].iter():\n",
    "#     for elem in method.iter():\n",
    "        if elem.text.strip():\n",
    "            words += 1\n",
    "            if words > threshold:\n",
    "                return words\n",
    "    return words\n",
    "    \n",
    "def get_tree_depth(element:ET.Element, level=0, threshold=4):\n",
    "    \"\"\"Return the depth of an ElementTree Element object.\"\"\"\n",
    "    if len(element) == 0:\n",
    "        return level\n",
    "    if level > threshold:\n",
    "        return level\n",
    "    return max(get_tree_depth(child, level + 1) for child in element)\n",
    "\n",
    "def compare_nodes(node1, node2): # NOT USED\n",
    "    \"\"\"Recursively compare the attributes and children of two XML nodes.\"\"\"\n",
    "    # Check if the tag and attributes of the nodes are equal\n",
    "    if node1.tag != node2.tag :#or node1.text != node2.attrib:\n",
    "        return False\n",
    "\n",
    "    # Check if the number of children of the nodes is equal\n",
    "    if len(node1) != len(node2):\n",
    "        return False\n",
    "\n",
    "    # Recursively compare the children of the nodes\n",
    "    for child1, child2 in zip(node1, node2):\n",
    "        if not compare_nodes(child1, child2):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def get_roots(file_path:str, DEPTH_THRESHOLD=4, WORDS_THRESHOLD=5) -> tp.List[tp.Dict]:\n",
    "    '''\n",
    "    :return: list of dicts {'element': ET.element, 'words', 'depth', 'method_name', 'path'}\n",
    "    '''\n",
    "    \n",
    "    tree = ET.parse(file_path)\n",
    "    class_name = tree.findtext('.TypeDeclaration/SimpleName')\n",
    "    if not class_name.startswith('CWE'):\n",
    "#         raise ValueError(f'Class name \"{class_name}\" does not starts with CWE')\n",
    "        print(f'Class name \"{class_name}\" does not starts with CWE')\n",
    "    \n",
    "    valid_methods = []\n",
    "        \n",
    "    for method in tree.findall('.//TypeDeclaration/MethodDeclaration'):\n",
    "        \n",
    "        method_name = method.findtext('.SimpleName')        \n",
    "        if not re.match('^(good|bad).*$', method_name):\n",
    "            continue\n",
    "        \n",
    "        depth = get_tree_depth(method, threshold=DEPTH_THRESHOLD)\n",
    "        if depth <= DEPTH_THRESHOLD:\n",
    "            continue\n",
    "        \n",
    "        words = method_words(method, WORDS_THRESHOLD)\n",
    "        if words <= WORDS_THRESHOLD:\n",
    "            continue\n",
    "            \n",
    "#         for elem in method.findall('.SimpleName'): # changing all <SimpleName> NAME </SimpleName> to hash(class, NAME)\n",
    "#             if re.search(r'^(good|bad).*', elem.text):                \n",
    "#                 elem.text = str(hash((class_name, elem.text)))\n",
    "                \n",
    "#         for elem in method.findall('.//MethodInvocation/SimpleName'): # changing all <SimpleName> NAME </SimpleName> to hash(class, NAME)\n",
    "#             if re.search(r'^(good|bad).*', elem.text):                \n",
    "#                 elem.text = str(hash((class_name, elem.text)))\n",
    "        \n",
    "        for elem in method.findall('.//SimpleName'): # changing all <SimpleName> NAME </SimpleName> to hash(class, NAME)\n",
    "            if re.search(r'^(good|bad).*', elem.text):                \n",
    "                elem.text = str(hash((class_name, elem.text)))\n",
    "                \n",
    "        valid_methods.append({\n",
    "            'element':method,\n",
    "#             'words':words,\n",
    "#             'depth':depth,\n",
    "            'method_name':method_name,\n",
    "#             'path': file_path,\n",
    "        })\n",
    "        \n",
    "    return valid_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "uTYwThcTu3Xh"
   },
   "outputs": [],
   "source": [
    "def xml_to_Data(path_to_xmls,) -> tp.Tuple[tp.List[Data], tp.List[DiGraph]]:\n",
    "    datas = [] \n",
    "    graphs = []\n",
    "    files = 0\n",
    "\n",
    "    for filename in tqdm(os.listdir(path_to_xmls)):\n",
    "        file_path = os.path.join(path_to_xmls, filename)\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "        method_roots = get_roots(file_path)\n",
    "        files += 1\n",
    "\n",
    "        for method in method_roots: \n",
    "            graph = build_graph(method['element'])\n",
    "            target = 1 if method['method_name'][:3] == 'bad' else 0\n",
    "            data = graph_to_data(graph, target)\n",
    "\n",
    "#             graphs.append(graph)\n",
    "            datas.append(data)        \n",
    "\n",
    "    print(f'Total files: {files}')\n",
    "    return [datas, graphs]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sVv8BmbidVH"
   },
   "source": [
    "# Начало тут\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqsMEcSyKd9v",
    "outputId": "76593996-2dd3-4445-a2f7-c3c13072a5c2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 46286/46286 [24:39<00:00, 31.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 46286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datas, graphs = xml_to_Data('C:/Users/Arkady/Downloads/Juliet_AST/Juliet_AST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128039"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_v2_0.pickle', 'wb') as f:\n",
    "    pickle.dump(datas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['MethodDeclaration'],\n",
       " ['Modifier'],\n",
       " ['public'],\n",
       " ['PrimitiveType'],\n",
       " ['void'],\n",
       " ['SimpleName'],\n",
       " ['-6391724344061429216'],\n",
       " ['SimpleType', 'SimpleName'],\n",
       " ['IOException'],\n",
       " ['Block'],\n",
       " ['VariableDeclarationStatement'],\n",
       " ['SimpleType', 'SimpleName'],\n",
       " ['InputStreamReader'],\n",
       " [['SimpleName'], ['NullLiteral'], ['VariableDeclarationFragment']],\n",
       " ['readerInputStream'],\n",
       " ['null'],\n",
       " ['VariableDeclarationStatement'],\n",
       " ['SimpleType', 'SimpleName'],\n",
       " ['BufferedReader'],\n",
       " [['SimpleName'], ['NullLiteral'], ['VariableDeclarationFragment']]]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas[0].x[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_v2_0_short.pickle', 'wb') as f:\n",
    "    pickle.dump(datas[:1000], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42JOCl64_oKP",
    "outputId": "52275b9a-9679-436f-cebc-25aee870eccb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53, 384])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_embedding(MODEL_NAME='all-MiniLM-L6-v2'):\n",
    "    '''\n",
    "    :return: returns callable function(data.x) -> torch.Tensor[num_nodes, EMBEDDING_SIZE]\n",
    "    '''\n",
    "    model = SentenceTransformer('sentence-transformers/' + MODEL_NAME, \n",
    "                                device = 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    EMBEDDING_SIZE = model.get_sentence_embedding_dimension()\n",
    "    embeddings = dict()\n",
    "\n",
    "    def encode_token(token:str):\n",
    "        if token not in embeddings.keys():\n",
    "            embeddings[token] = model.encode(token)\n",
    "#             print(f'encoded new token: {token}')\n",
    "        return embeddings[token]\n",
    "    \n",
    "    def f(args:tp.List[tp.List[tp.List]] = []):\n",
    "        # args =  [[['SimpleType', 'SimpleName'], ['SimpleName'], ['SingleVariableDeclaration']], ...]\n",
    "        # :return: torch.Tensor[len(args), EMBEDDING_SIZE]\n",
    "        embs_0 = torch.zeros([len(args), EMBEDDING_SIZE], dtype=torch.float)\n",
    "\n",
    "        for i, arg_1 in enumerate(args): \n",
    "            # node = [['SimpleType', 'SimpleName'], ['SimpleName'], ['SingleVariableDeclaration']]\n",
    "            embs_1 = torch.zeros(EMBEDDING_SIZE)\n",
    "            \n",
    "            if isinstance(arg_1, str):\n",
    "                embs_0[i] = encode_token(arg_1)\n",
    "                continue\n",
    "            \n",
    "            for arg_2 in arg_1: # arg = ['SimpleType', 'SimpleName']\n",
    "                embs_2 = torch.zeros(EMBEDDING_SIZE)\n",
    "                if isinstance(arg_2, str):\n",
    "                    embs_1 += encode_token(arg_2)\n",
    "                    continue\n",
    "                    \n",
    "                for token in arg_2: # token = 'SimpleType'\n",
    "                    embs_2 += encode_token(token)\n",
    "                embs_2 /= len(arg_2)\n",
    "                embs_1 += embs_2\n",
    "\n",
    "            embs_1 /= len(arg_1)\n",
    "            embs_0[i] = embs_1\n",
    "\n",
    "        return embs_0\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "emb = create_embedding()\n",
    "s = datas[0].x\n",
    "e = emb(datas[3].x)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_emb = get_embedding()\n",
    "\n",
    "with open('data_v2_0_short.pickle', 'rb') as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0016,  0.1044,  0.0081,  ...,  0.0169,  0.0683,  0.0132],\n",
       "        [-0.0481,  0.0820, -0.0293,  ...,  0.0727, -0.0073, -0.0837],\n",
       "        [-0.0344,  0.0216, -0.0430,  ...,  0.0538, -0.0877,  0.0188],\n",
       "        ...,\n",
       "        [-0.0376,  0.0746, -0.0152,  ...,  0.0045,  0.0392, -0.0632],\n",
       "        [-0.0895, -0.0681, -0.0692,  ..., -0.0215,  0.0204, -0.0557],\n",
       "        [-0.0973, -0.0501, -0.0441,  ...,  0.0514, -0.0049, -0.0276]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ZTSDKMiKwo8",
    "outputId": "5bbd7016-a775-471b-d47f-58c05aa83d56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 64.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3247e+01, -1.7360e+01,  1.6009e+01,  1.4016e+01, -3.5395e+01,\n",
       "         4.6722e+01, -3.1937e+01,  2.9005e+01,  1.5794e+00,  6.3628e+00,\n",
       "         4.5635e+01, -1.1611e+01,  3.3276e+01,  4.9039e+01, -1.5933e+01,\n",
       "         6.1741e+00, -1.4937e+01, -9.2308e+00,  1.4600e+01, -2.0914e+01,\n",
       "        -4.6614e+01,  2.2514e+01, -1.9158e+01, -5.9237e+00, -2.9356e+01,\n",
       "        -6.1191e+00, -2.4338e+00, -1.5150e+01, -1.5961e+01,  2.2583e+01,\n",
       "         1.8625e+01,  2.8759e+01, -3.0815e+01,  1.5404e+01,  2.0227e-03,\n",
       "        -2.1144e+01, -1.8557e+01, -5.6416e+00, -2.4728e+01,  3.2059e+01,\n",
       "        -3.4298e+01,  1.9746e+01, -2.0892e+01, -1.5802e+01, -9.2973e+00,\n",
       "        -1.4842e+01,  1.8361e+01,  1.0652e+01, -1.7804e+01,  8.0665e+00,\n",
       "         1.8526e+00, -3.1671e+01,  1.6687e+01, -3.6816e-01,  6.3781e+01,\n",
       "        -4.7884e+01,  2.7504e+01,  2.8632e+01, -1.8908e+01,  2.8738e+01,\n",
       "         1.2851e+01,  2.6709e+01,  1.6451e+01, -8.5416e+00,  1.3588e+01,\n",
       "         1.4132e+01,  5.8880e+00,  1.3587e+00,  2.8317e+01,  1.0914e+01,\n",
       "         3.9193e+01,  5.8790e+00,  2.6265e+01,  8.5708e+01, -2.2048e+01,\n",
       "        -2.9851e+00, -2.5205e+01,  7.1051e+00, -1.3577e+01, -2.6269e+01,\n",
       "        -6.3398e+01,  1.5265e+01,  2.3107e+01,  1.9331e+01,  3.6102e+01,\n",
       "        -7.2089e+00,  1.2854e+01,  1.5553e+01, -3.0535e+01, -1.9336e+01,\n",
       "         7.5955e+00, -2.3817e+01,  1.0743e+01,  9.1050e+00,  1.4914e+01,\n",
       "        -2.5603e+00, -2.1738e+01,  9.9841e+00, -3.0526e+01, -5.9718e+01,\n",
       "        -3.6825e+01,  1.7014e+01,  6.5105e+01, -4.0645e-01, -2.6293e+01,\n",
       "         1.4844e+00,  2.6905e+01, -1.9893e+00, -1.9463e+01, -7.6653e+00,\n",
       "        -1.5822e+01, -1.0981e+01, -5.0778e+01,  3.2539e+01,  5.3591e+01,\n",
       "         1.7969e+01, -9.9265e+00,  1.0683e+00,  2.9939e+01,  2.7121e+01,\n",
       "         3.2717e+01, -6.0837e+00,  1.8028e+01,  1.9541e+01, -4.9168e-02,\n",
       "        -1.2778e+01, -2.3393e+01, -3.6494e+00,  8.4864e+00, -2.7858e+01,\n",
       "        -3.9289e-01, -1.7455e+01, -8.8107e+00, -3.7525e+01,  2.3741e+01,\n",
       "         3.2351e+01, -1.9508e+00, -1.8421e+01,  3.0191e+01, -4.7014e+00,\n",
       "        -8.0081e+00,  8.1887e+00,  5.0867e+00, -3.0136e+01, -3.0221e+00,\n",
       "        -3.4117e+00,  6.5415e+00,  2.4454e+01,  6.7285e+00, -1.5516e+01,\n",
       "         4.4758e+01, -1.8762e+00, -3.9343e+01,  1.4488e+00,  4.0690e+01,\n",
       "        -7.4071e+00,  1.0968e+00, -4.0466e+01, -4.1428e+00,  7.0128e+00,\n",
       "         1.8802e+01, -1.8719e+01, -2.5417e+00, -2.1669e+01, -2.3225e+01,\n",
       "         1.0571e+01,  3.9344e+00, -1.2741e+01, -3.4549e+01, -4.2073e+01,\n",
       "        -3.6439e+01, -2.3329e+01, -4.5358e+00, -2.9903e+01,  3.1032e+01,\n",
       "         2.2513e+01,  2.2457e+01, -2.8614e+00, -6.5426e+01, -3.8285e+01,\n",
       "        -3.0250e+00, -1.4537e+02, -1.3338e+01,  1.8835e+01,  9.2651e-01,\n",
       "         2.1493e+01,  2.3190e+01, -3.9693e-01, -2.9552e+01, -9.9112e+00,\n",
       "         1.4330e+01,  3.8770e+00,  5.9684e+00,  4.4193e+01,  1.2756e+01,\n",
       "        -1.6279e+01,  1.2689e+01, -7.6190e+00, -6.2495e+00,  1.7848e+01,\n",
       "        -2.3083e+01, -3.1495e+01,  4.2209e+01,  6.5310e+00,  8.8462e-01,\n",
       "         2.7116e+01,  1.6839e+01, -2.5739e+01,  3.1995e+01, -4.8575e+01,\n",
       "        -6.0451e+00,  1.5716e+01, -5.6957e-01,  1.6574e+01, -1.3977e+01,\n",
       "         3.8558e+01,  1.6887e+01, -7.4146e+00, -4.2364e-01, -1.0204e+01,\n",
       "        -7.6047e+00,  2.3628e-01,  3.1011e+01, -6.7401e+00, -2.8404e+00,\n",
       "        -6.1215e+00, -2.3764e+01, -1.0635e+01,  3.4075e+00,  1.6317e+00,\n",
       "         2.0120e+01,  2.1848e+01,  4.7538e+00,  8.7785e+00,  3.7162e-01,\n",
       "        -1.4476e+01,  2.9382e+01, -4.7920e+01,  1.2765e+00, -5.2944e+01,\n",
       "         2.8560e+01,  4.1819e+01,  1.3683e+01,  3.4195e+01,  5.3394e+01,\n",
       "        -2.4228e+01,  3.0199e+01, -5.2908e+00, -1.9079e+01, -3.1914e+01,\n",
       "        -3.1284e+01,  4.2330e+01,  3.2062e+00,  1.8971e+01,  2.1443e+01,\n",
       "        -7.2181e-01, -3.8148e+01,  2.1328e+01, -3.5669e+01,  3.4187e+01,\n",
       "         1.6911e+01, -3.4348e+01,  7.5010e+00, -2.0899e+01,  2.4736e+01,\n",
       "         5.5627e-01, -2.5889e+01,  1.6205e+01,  1.5704e+01, -7.5670e-01,\n",
       "        -1.1186e+01,  3.5161e+01,  1.3664e+01, -8.1352e+00,  4.2988e-01,\n",
       "        -8.4195e-01, -4.5020e+01, -1.2984e+01, -2.3928e+01, -2.6347e+01,\n",
       "         9.8835e-01,  1.8342e+01,  1.8878e+01, -2.5705e+01,  1.0646e+01,\n",
       "         3.9020e+01, -1.3788e+01, -5.3131e+01, -1.2302e+01, -1.2040e+01,\n",
       "        -4.4200e+01, -2.2967e+01,  7.5940e+00, -5.8544e+01,  8.4237e-01,\n",
       "         2.0605e+01, -4.2861e+01,  1.0375e+01,  2.9262e+01, -1.2695e+01,\n",
       "        -1.7895e+01, -1.3287e+01, -2.9762e+00, -3.6167e+01, -8.6293e+00,\n",
       "        -2.7352e+01,  4.4286e+00,  1.7986e+01,  1.4099e+01,  1.0322e+01,\n",
       "         3.8056e+01,  4.3532e-01, -2.7122e+01, -1.5489e+01,  1.8807e+01,\n",
       "         2.0725e+01,  2.8444e+01, -1.2335e+01, -1.3687e+01,  8.5961e+00,\n",
       "        -1.6512e+01,  2.2750e+01,  9.0217e+00, -6.2676e+00,  1.9627e+01,\n",
       "         7.8390e-01, -3.2470e+01,  4.3541e+01, -1.3757e+01, -2.9560e+01,\n",
       "         1.5530e+01,  1.8669e+00, -2.4947e+01,  3.0901e+01,  1.3871e+01,\n",
       "        -6.0079e+01, -1.1043e+01, -5.5732e+01,  2.3246e+01,  3.3822e+01,\n",
       "        -1.2165e+01,  1.1169e+01, -2.2220e+01, -2.5195e+01, -5.1763e+01,\n",
       "         9.1848e+00,  2.2120e+01, -1.0926e+01, -1.6015e+01, -6.7228e-02,\n",
       "        -4.9643e+00,  3.7481e+01, -3.5697e+00, -9.0878e+00,  4.8348e-01,\n",
       "        -1.6965e+01,  1.5716e+01,  5.8802e+00, -8.7520e+00, -3.2458e+01,\n",
       "         8.0463e+00,  3.5453e+01,  1.7491e+01,  5.6607e+00, -1.6079e+01,\n",
       "         3.4794e+01,  1.9382e+01, -5.6965e+00, -5.4239e-01, -1.4638e+01,\n",
       "        -9.4862e-01,  6.5837e+00,  1.6437e+01,  3.0021e+01, -1.8047e+01,\n",
       "         1.7883e+01,  1.4716e+01,  1.5688e+01, -2.1292e+00, -4.2720e+00,\n",
       "        -1.2397e+01, -1.3353e+01, -1.8152e+01,  3.1600e+01,  4.5627e+00,\n",
       "        -1.0896e+01,  2.6617e+01,  3.0153e+00, -1.7574e+01, -2.7945e+00,\n",
       "         4.5237e+01, -3.0842e+01, -4.8186e+01,  1.8897e+01,  2.2633e+01,\n",
       "        -2.4249e+01, -1.0283e+01,  3.1217e+01, -6.3380e+00,  2.7814e+01,\n",
       "         8.2091e+00,  5.0990e+01,  4.1866e+00,  5.4998e+01, -3.5356e+01,\n",
       "         9.1880e+00,  2.0546e+01, -3.6906e+00,  2.7171e+01, -4.6243e+01,\n",
       "        -4.5892e+00, -1.5937e+01,  1.1132e+01,  3.4962e+01, -3.0259e+01,\n",
       "        -3.1863e+01, -2.1379e+01, -4.3572e+01,  1.7808e+01, -6.1589e+01,\n",
       "        -1.3519e+01,  2.7242e+01, -1.7952e+01,  2.1174e+01, -2.0890e+01,\n",
       "         2.6213e+01,  2.2807e+01, -2.0709e+01,  2.4379e+01, -2.8334e+00,\n",
       "         1.2957e+01, -1.9258e+01,  4.5486e+00,  3.3412e+01, -2.0891e+01,\n",
       "        -5.9358e+01,  2.0722e+01,  6.1884e+01, -1.6810e+01,  1.5602e+00,\n",
       "         1.1159e+01, -3.1012e+00, -5.3385e+00, -3.8639e+00,  3.4772e+00,\n",
       "        -9.4094e+00, -3.8270e+01,  1.9805e+01, -1.2115e+01,  7.4320e+00,\n",
       "         1.9581e+01, -5.2621e+01, -7.1352e+00, -1.5599e+01, -1.4227e+01,\n",
       "        -8.1329e+00,  3.8165e+01, -1.5910e+01, -2.3167e+00, -9.2361e+00,\n",
       "         5.4723e+01,  2.0432e+01, -1.8437e+01,  3.8641e+00, -5.1767e+00,\n",
       "        -4.0537e+01, -3.0506e+01,  5.0932e+00,  1.8792e+01, -2.9253e+01,\n",
       "        -2.8056e+00,  8.7152e+00, -6.5918e+00, -1.0020e+00, -3.0465e+00,\n",
       "        -2.7919e+01, -8.2169e+00, -4.3130e+01, -1.0334e+01, -1.0094e+01,\n",
       "        -1.3831e+01, -9.9108e+00, -3.8225e+00, -6.6261e+01,  2.7568e+01,\n",
       "        -4.6351e+00,  3.7797e+01,  5.6508e+00,  9.6727e+00,  3.1520e+01,\n",
       "         4.4325e-01, -2.9565e+01, -9.8889e+00, -2.7764e+01, -1.3618e+01,\n",
       "        -1.8506e-01,  3.6306e+01, -4.1226e+01,  8.8435e-01,  1.4509e+01,\n",
       "         7.1202e+00,  3.0135e+00, -9.8589e+00,  3.2507e+01,  2.2165e+01,\n",
       "        -2.2165e+01, -4.6716e+00, -2.7126e+01, -4.3301e+00, -5.7642e+00,\n",
       "         2.9539e+01,  3.5686e+01, -1.5706e+01,  7.1748e+00,  2.2947e+01,\n",
       "        -2.4276e+01,  2.9650e+01, -1.1310e+01, -1.3936e+01, -7.5176e+00,\n",
       "         5.1797e+00, -1.3522e+01,  3.4196e+01, -9.2310e+00, -2.5596e+01,\n",
       "         1.8383e+01,  3.1226e+01, -3.1114e+01,  1.1524e+01,  2.2468e+00,\n",
       "        -4.8793e+00,  1.0420e+01,  2.6863e+01,  4.0223e+00, -2.2605e+01,\n",
       "         4.8824e+01,  4.3562e+00,  3.1465e+01, -2.3063e+01,  1.5456e+01,\n",
       "         3.3381e+01, -2.7824e+01,  9.6417e+00,  9.3359e+00,  1.2676e+01,\n",
       "         7.1233e+01,  2.7837e+01,  1.5676e+01, -2.2441e+01, -4.7914e+01,\n",
       "         2.0929e+01,  2.1713e+01, -5.7435e+01,  5.5160e+00, -1.0047e+01,\n",
       "        -6.8732e-30,  4.9256e+00, -1.2091e+01, -1.0656e+01,  1.9487e+01,\n",
       "        -6.2505e+01, -5.2879e+01,  3.2704e+01,  1.9717e+01, -2.0895e+01,\n",
       "        -6.0174e+00, -3.3584e-01, -1.4435e+01,  1.8329e+01,  1.6442e+01,\n",
       "         3.3866e+01, -2.1268e+01,  2.3384e+01, -7.2912e+00,  1.1033e+01,\n",
       "        -7.2222e+00, -1.3788e+01,  2.1141e+01,  3.1977e+01,  4.2292e+01,\n",
       "        -1.5745e+01, -1.8146e+01,  3.2576e+01,  1.9016e+00,  2.7154e+01,\n",
       "         2.3708e+01,  9.0090e+00,  2.8872e+01, -1.7880e+01,  3.3636e+01,\n",
       "         1.6327e+00,  3.4995e+01, -3.2042e+01, -1.7850e+01,  2.8023e+00,\n",
       "         2.5094e+01, -2.8484e+01, -4.5139e+01, -1.3529e+01, -1.3909e+01,\n",
       "        -3.3435e+01, -1.4215e+01,  1.6312e+01, -5.3682e+01, -2.5931e+01,\n",
       "         1.1479e+01, -3.2464e-01, -2.4436e+00, -2.3914e+01, -6.7617e+01,\n",
       "        -1.0369e+01,  2.6454e+01, -3.2720e-01, -3.4589e+01, -2.8625e+01,\n",
       "        -1.8947e+00, -2.8072e+00,  4.7319e+00, -1.7152e+01,  2.1892e+01,\n",
       "         2.0196e+01, -1.3574e+00,  1.2815e+01, -4.3612e+01,  1.2406e+01,\n",
       "         1.4947e+01, -7.7300e+00,  2.4313e+01,  1.6753e+01, -2.8104e+01,\n",
       "        -2.2030e+01, -2.3603e+01,  8.9256e+00,  1.1338e+01,  1.5675e+01,\n",
       "        -4.8907e+00,  2.6568e+00, -3.1444e+01,  1.5991e+01, -7.0888e+00,\n",
       "        -1.6159e+01,  1.4095e-01, -5.2864e+00, -1.2018e+01,  1.6558e+00,\n",
       "        -1.1944e+01,  2.3895e+00, -1.6700e+01,  6.8641e+00, -9.9180e+00,\n",
       "        -1.8206e+01, -2.2894e+01,  9.1980e+00, -1.3608e+01, -1.3226e+01,\n",
       "        -2.5342e+00,  4.7699e+01,  2.1172e+01,  7.5985e+00,  3.6973e+01,\n",
       "        -1.1933e+01, -1.1348e+00, -3.3254e+01,  1.6797e+01,  1.0294e+00,\n",
       "        -2.1926e+01, -1.2714e+01, -7.4135e+00,  1.9428e+01,  3.3037e+01,\n",
       "         9.2176e+00,  2.6067e+01, -5.2325e+00, -2.3903e+01, -2.2762e+01,\n",
       "        -1.2957e+00,  2.8428e+01, -1.1990e+01, -2.7800e+01,  1.7728e+01,\n",
       "        -7.2138e+00,  6.0962e+01, -3.3158e+01,  4.4090e+01, -3.6567e+00,\n",
       "         9.9974e+00,  1.5739e+01,  7.1621e+00,  2.7041e-04, -3.2601e+01,\n",
       "         1.0825e+01, -1.2337e+01, -2.0537e+01, -2.2774e+01,  1.3887e+01,\n",
       "        -8.8633e+00, -3.5825e+00, -3.8127e+01, -3.7292e+01,  1.0341e+00,\n",
       "        -1.3919e+01,  5.5672e+01, -2.4314e+01,  7.2079e+00, -1.7371e+01,\n",
       "        -1.5420e+01,  7.9347e+00, -7.2631e+00, -1.6405e+01,  1.5358e+01,\n",
       "         2.9067e+00,  4.9277e+01,  1.2036e+01, -1.9246e+00,  2.1271e+01,\n",
       "        -5.2410e+00, -6.3035e+01,  4.1905e+01, -2.2938e+01,  1.0063e+01,\n",
       "        -6.8222e+00,  5.7278e+00, -6.5642e+00,  3.1013e+01, -4.5188e+01,\n",
       "         5.1215e+01,  9.7987e-02,  5.2309e+00, -2.4710e+01, -6.5859e+00,\n",
       "        -1.7398e+01, -1.5715e+01,  1.5249e+01,  3.6617e+01,  3.0239e+00,\n",
       "        -4.7474e+00,  3.0042e+01, -4.7798e+01, -1.7509e+01, -2.3891e+01,\n",
       "         2.3148e+01,  2.7910e+01,  3.4501e+01,  3.0125e+01, -1.5077e+01,\n",
       "         2.1230e+01,  5.1068e+00, -1.1500e+01, -2.1509e+01, -7.8238e+00,\n",
       "        -3.0626e+01,  4.5165e+01,  4.8205e+01,  2.9599e+01,  3.0440e+01,\n",
       "        -4.1874e+00,  1.6443e-31,  7.7959e+00, -1.6689e-01,  1.5807e+01,\n",
       "         2.3608e+01, -1.2703e+01, -3.8016e-01,  1.3947e+01,  6.5447e-01,\n",
       "         2.2113e+01, -5.2603e+01, -5.8801e+00])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'all-mpnet-base-v2'\n",
    "# MODEL_NAME = 'all-MiniLM-L6-v2' # ~ 2 times faster, slightly worse quality\n",
    "model = SentenceTransformer('sentence-transformers/' + MODEL_NAME, \n",
    "                                device = 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.zeros(model.get_sentence_embedding_dimension())\n",
    "for i in tqdm(range(1000)):\n",
    "  s = generate_random_string(10)\n",
    "  x += model.encode(s)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i61s4nuUIrQ4",
    "outputId": "1e386a90-c8fd-4fdc-fa93-bdcde6a10b8e"
   },
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('sentence-transformers/' + MODEL_NAME, \n",
    "#                                 device = 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# x = torch.zeros(384)\n",
    "# for i in tqdm(range(10000)):\n",
    "#   s = generate_random_string(20)\n",
    "#   x += model.encode(s)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "kFZwcR17rmp6",
    "outputId": "5b3ccbb0-0482-469e-ac17-17eb1d2fd9e7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'123'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import tp\n",
    "\n",
    "from embedding import create_embedding   # !\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, embedding=create_embedding):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "        self.embedding = create_embedding()  # !\n",
    "\n",
    "    def forward(self, data):\n",
    "        x:tp.List[str] = data.x            # !\n",
    "        x:torch.Tensor = self.embedding(x) # !\n",
    "\n",
    "        edge_index = data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
