{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybGy3TXnOibF",
    "outputId": "37d9390f-3d97-4ea5-f95a-2fe6d45d56bc"
   },
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install torch_geometric\n",
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZKlyiXQNPEld"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "import typing as tp\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.classes.digraph import DiGraph\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "qyCKZywxlyki"
   },
   "outputs": [],
   "source": [
    "# Building graph\n",
    "def dfs_build_graph(root_node:ET.Element) -> tp.Tuple[DiGraph, tp.List, str]:\n",
    "    graph = nx.DiGraph() \n",
    "\n",
    "    leafs = []\n",
    "    root_name = 0\n",
    "    suf = iter(range(10_000_000))\n",
    "\n",
    "    def dfs(vertice:ET.Element) -> str:\n",
    "        # Extract node name in AST\n",
    "\n",
    "        tag = vertice.tag # XML tag like <SimpleName>\n",
    "\n",
    "        node = next(suf)\n",
    "        node_name = tag   \n",
    "\n",
    "        graph.add_node(node, text=[node_name])\n",
    "#         graph.add_node(node, text=node_name)\n",
    "        \n",
    "        # Recursively traverse the child nodes\n",
    "        for child in vertice:\n",
    "            child_node = dfs(child)\n",
    "            graph.add_edge(child_node, node)\n",
    "          \n",
    "        if len(vertice) == 0:\n",
    "            leaf_node = next(suf)\n",
    "            leaf_name = vertice.text.strip()\n",
    "\n",
    "            graph.add_node(leaf_node, text=[leaf_name])\n",
    "#             graph.add_node(leaf_node, text=leaf_name)\n",
    "            graph.add_edge(leaf_node, node)\n",
    "\n",
    "            leafs.append(leaf_node)\n",
    "            \n",
    "        return node\n",
    "\n",
    "    # TODO: add sink and leafs edges here, not outside\n",
    "    \n",
    "    dfs(root_node)\n",
    "\n",
    "    return (graph, leafs, root_name)\n",
    "\n",
    "# Merging Single-Entry Node Sequences\n",
    "def dfs_merge_sequences(graph, node: str):\n",
    "  # node: str, key of node in graph.nodes\n",
    "\n",
    "  nodes_one_succ = []\n",
    "\n",
    "  while(graph.in_degree(node) == 1):\n",
    "      nodes_one_succ.append(node)\n",
    "      node = list(graph.predecessors(node))[0]\n",
    "\n",
    "  # leaf nodes sholdn't be merged, so in_degree != 0\n",
    "\n",
    "  if len(nodes_one_succ) > 1:\n",
    "      parent = nodes_one_succ[0]\n",
    "\n",
    "      for child in nodes_one_succ[1:]:\n",
    "          nx.contracted_nodes(graph, parent, child, self_loops=False, copy=False)\n",
    "\n",
    "      # concatenate tokens of merged vertices\n",
    "      p = graph.nodes(data=True)[parent]\n",
    "        \n",
    "      p['text'] = p['text'] + [args['text'][0] for args in p['contraction'].values()]\n",
    "#       p['text'] += ',' + ','.join(args['text'] for args in p['contraction'].values()) # TODO\n",
    "\n",
    "      del p['contraction']\n",
    "\n",
    "  # now node is either a leaf or has degree >= 2\n",
    "\n",
    "  for child in graph.predecessors(node):\n",
    "      dfs_merge_sequences(graph, child)\n",
    "\n",
    "# Merging Aggregation Structures\n",
    "# TODO: merge only vertices with specific AST node names\n",
    "def dfs_merge_aggregations(graph, node: str):\n",
    "\n",
    "    # Recursively traverse the child nodes\n",
    "    children_degs = [graph.in_degree(child) for child in graph.predecessors(node)]\n",
    "    \n",
    "    if not children_degs:\n",
    "        # node is a leaf\n",
    "        return\n",
    "\n",
    "    if len(children_degs) >= 2 and max(children_degs) <= 1: # TODO\n",
    "        # all children are either have deg=1 or a leaf\n",
    "        # merging node and children\n",
    "        children = list(graph.predecessors(node))\n",
    "        \n",
    "        for child in (children):\n",
    "            nx.contracted_nodes(graph, node, child, self_loops=False, copy=False)\n",
    "        \n",
    "        parent = graph.nodes(data=True)[node]\n",
    "        parent['text'] = [args['text'] for args in parent['contraction'].values()] + [parent['text']]\n",
    "#         parent['text'] += '|' + \\\n",
    "#             '|'.join([args['text'] for args in parent['contraction'].values()]) # TODO\n",
    "        del parent['contraction']\n",
    "\n",
    "    for child in graph.predecessors(node):\n",
    "        dfs_merge_aggregations(graph, child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "qZGKD_SiFxNM"
   },
   "outputs": [],
   "source": [
    "def build_graph(root_node:ET.Element) -> DiGraph:\n",
    "    \n",
    "    graph, leafs, root_name = dfs_build_graph(root_node)\n",
    "\n",
    "    dfs_merge_sequences(graph, root_name)\n",
    "    dfs_merge_aggregations(graph, root_name)\n",
    "\n",
    "    # Adding edges between leafs (consequent initial code tokens)\n",
    "    for u, v in zip(leafs[:-1], leafs[1:]):\n",
    "        graph.add_edge(u, v)\n",
    "\n",
    "    # Adding ROOT node - global graph's sink\n",
    "    for v in graph.nodes:\n",
    "        if v != root_name:\n",
    "            graph.add_edge(v, root_name)\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "4mRxMTwyEyTQ"
   },
   "outputs": [],
   "source": [
    "def graph_to_data(graph:DiGraph, target:int) -> Data:\n",
    "    graph = nx.convert_node_labels_to_integers(graph)\n",
    "    return Data(edge_index=torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous().view(2, -1),\n",
    "                edge_attr=None,\n",
    "                x=list(nx.get_node_attributes(graph, 'text').values()),\n",
    "                y=target\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_words(method, threshold=1e6):\n",
    "    words = 0\n",
    "    if not method.findall('.Block'):\n",
    "        return 0\n",
    "    for elem in method.findall('.Block')[0].iter():\n",
    "#     for elem in method.iter():\n",
    "        if elem.text.strip():\n",
    "            words += 1\n",
    "            if words > threshold:\n",
    "                return words\n",
    "    return words\n",
    "    \n",
    "def get_tree_depth(element:ET.Element, level=0, threshold=4):\n",
    "    \"\"\"Return the depth of an ElementTree Element object.\"\"\"\n",
    "    if len(element) == 0:\n",
    "        return level\n",
    "    if level > threshold:\n",
    "        return level\n",
    "    return max(get_tree_depth(child, level + 1) for child in element)\n",
    "\n",
    "def compare_nodes(node1, node2): # NOT USED\n",
    "    \"\"\"Recursively compare the attributes and children of two XML nodes.\"\"\"\n",
    "    # Check if the tag and attributes of the nodes are equal\n",
    "    if node1.tag != node2.tag :#or node1.text != node2.attrib:\n",
    "        return False\n",
    "\n",
    "    # Check if the number of children of the nodes is equal\n",
    "    if len(node1) != len(node2):\n",
    "        return False\n",
    "\n",
    "    # Recursively compare the children of the nodes\n",
    "    for child1, child2 in zip(node1, node2):\n",
    "        if not compare_nodes(child1, child2):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def get_roots(file_path:str, DEPTH_THRESHOLD=4, WORDS_THRESHOLD=5) -> tp.List[tp.Dict]:\n",
    "    '''\n",
    "    :return: list of dicts {'element': ET.element, 'words', 'depth', 'method_name', 'path'}\n",
    "    '''\n",
    "    \n",
    "    tree = ET.parse(file_path)\n",
    "    class_name = tree.findtext('.TypeDeclaration/SimpleName')\n",
    "    if not class_name.startswith('CWE'):\n",
    "#         raise ValueError(f'Class name \"{class_name}\" does not starts with CWE')\n",
    "        print(f'Class name \"{class_name}\" does not starts with CWE')\n",
    "    \n",
    "    valid_methods = []\n",
    "        \n",
    "    for method in tree.findall('.//TypeDeclaration/MethodDeclaration'):\n",
    "        \n",
    "        method_name = method.findtext('.SimpleName')        \n",
    "        if not re.match('^(good|bad).*$', method_name):\n",
    "            continue\n",
    "        \n",
    "        depth = get_tree_depth(method, threshold=DEPTH_THRESHOLD)\n",
    "        if depth <= DEPTH_THRESHOLD:\n",
    "            continue\n",
    "        \n",
    "        words = method_words(method, WORDS_THRESHOLD)\n",
    "        if words <= WORDS_THRESHOLD:\n",
    "            continue\n",
    "            \n",
    "#         for elem in method.findall('.SimpleName'): # changing all <SimpleName> NAME </SimpleName> to hash(class, NAME)\n",
    "#             if re.search(r'^(good|bad).*', elem.text):                \n",
    "#                 elem.text = str(hash((class_name, elem.text)))\n",
    "                \n",
    "#         for elem in method.findall('.//MethodInvocation/SimpleName'): # changing all <SimpleName> NAME </SimpleName> to hash(class, NAME)\n",
    "#             if re.search(r'^(good|bad).*', elem.text):                \n",
    "#                 elem.text = str(hash((class_name, elem.text)))\n",
    "        \n",
    "        for elem in method.findall('.//SimpleName'): # changing all <SimpleName> NAME </SimpleName> to hash(class, NAME)\n",
    "            if re.search(r'^(good|bad).*', elem.text):                \n",
    "                elem.text = str(hash((class_name, elem.text)))\n",
    "                \n",
    "        valid_methods.append({\n",
    "            'element':method,\n",
    "#             'words':words,\n",
    "#             'depth':depth,\n",
    "            'method_name':method_name,\n",
    "#             'path': file_path,\n",
    "        })\n",
    "        \n",
    "    return valid_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "uTYwThcTu3Xh"
   },
   "outputs": [],
   "source": [
    "def xml_to_Data(path_to_xmls,) -> tp.Tuple[tp.List[Data], tp.List[DiGraph]]:\n",
    "    datas = [] \n",
    "    graphs = []\n",
    "    files = 0\n",
    "\n",
    "    for filename in tqdm(os.listdir(path_to_xmls)):\n",
    "        file_path = os.path.join(path_to_xmls, filename)\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "        method_roots = get_roots(file_path)\n",
    "        files += 1\n",
    "\n",
    "        for method in method_roots: \n",
    "            graph = build_graph(method['element'])\n",
    "            target = 1 if method['method_name'][:3] == 'bad' else 0\n",
    "            data = graph_to_data(graph, target)\n",
    "\n",
    "#             graphs.append(graph)\n",
    "            datas.append(data)        \n",
    "\n",
    "    print(f'Total files: {files}')\n",
    "    return [datas, graphs]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sVv8BmbidVH"
   },
   "source": [
    "# Начало тут\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqsMEcSyKd9v",
    "outputId": "76593996-2dd3-4445-a2f7-c3c13072a5c2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 46286/46286 [24:39<00:00, 31.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 46286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datas, graphs = xml_to_Data('C:/Users/Arkady/Downloads/Juliet_AST/Juliet_AST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128039"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_v2_0.pickle', 'wb') as f:\n",
    "    pickle.dump(datas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['MethodDeclaration'],\n",
       " ['Modifier'],\n",
       " ['public'],\n",
       " ['PrimitiveType'],\n",
       " ['void'],\n",
       " ['SimpleName'],\n",
       " ['-6391724344061429216'],\n",
       " ['SimpleType', 'SimpleName'],\n",
       " ['IOException'],\n",
       " ['Block'],\n",
       " ['VariableDeclarationStatement'],\n",
       " ['SimpleType', 'SimpleName'],\n",
       " ['InputStreamReader'],\n",
       " [['SimpleName'], ['NullLiteral'], ['VariableDeclarationFragment']],\n",
       " ['readerInputStream'],\n",
       " ['null'],\n",
       " ['VariableDeclarationStatement'],\n",
       " ['SimpleType', 'SimpleName'],\n",
       " ['BufferedReader'],\n",
       " [['SimpleName'], ['NullLiteral'], ['VariableDeclarationFragment']]]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas[0].x[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_v2_0_short.pickle', 'wb') as f:\n",
    "    pickle.dump(datas[:1000], f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
