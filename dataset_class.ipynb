{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg1sanzgoonf"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, List, Optional\n",
        "import torch\n",
        "import pickle\n",
        "from torch_geometric.data import Data, InMemoryDataset, Dataset, download_url\n",
        "from torch_geometric.utils import index_sort\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IMCAG(InMemoryDataset):\n",
        "    url = 'https://github.com/username/repos_name/raw/branchname'\n",
        "  \n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "          super().__init__(root, transform, pre_transform)\n",
        "          self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "    \n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        # The name of the files in the self.raw_dir folder that must be present in order to skip downloading.\n",
        "        return ['data_1.pickle', 'data_2.pickle']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        # The name of the files in the self.processed_dir folder that must be present in order to skip processing.\n",
        "        return ['data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        for f in self.raw_file_names:\n",
        "            download_url(os.path.join(self.url, f), self.raw_dir)\n",
        "    \n",
        "    def load_pickle(self, path: str):\n",
        "        with open(path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        return data\n",
        "\n",
        "    def process(self):\n",
        "        data_list = []\n",
        "        files = [f for f in os.listdir(self.raw_dir) if not os.path.isdir(f)]\n",
        "        for f in files:\n",
        "            data_list.extend(self.load_pickle(os.path.join(self.raw_dir, f)))\n",
        "\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(data) for data in data_list]\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])"
      ],
      "metadata": {
        "id": "NGaDfdsdpKmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CAG(Dataset):\n",
        "    url = 'https://github.com/username/repos_name/raw/branchname'\n",
        "  \n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "    \n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        # The name of the files in the self.raw_dir folder that must be present in order to skip downloading.\n",
        "        return ['data_1.pickle', 'data_2.pickle']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "         # The name of the files in the self.processed_dir folder that must be present in order to skip processing.\n",
        "        return ['data.pt', ...]\n",
        "\n",
        "    def download(self):\n",
        "        for f in self.raw_file_names:\n",
        "            download_url(os.path.join(self.url, f), self.raw_dir)\n",
        "    \n",
        "    def load_pickle(self, path: str):\n",
        "        with open(path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        return data\n",
        "\n",
        "    def process(self):\n",
        "        idx = 0\n",
        "        for raw_path in self.raw_paths:\n",
        "            data = self.load_pickle(raw_path)\n",
        "\n",
        "            if self.pre_filter is not None and not self.pre_filter(data):\n",
        "                continue\n",
        "\n",
        "            if self.pre_transform is not None:\n",
        "                data = self.pre_transform(data)\n",
        "            \n",
        "            for graph in data:\n",
        "                torch.save(graph, os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "                idx += 1\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "        return data"
      ],
      "metadata": {
        "id": "VzbNcD93iyFm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}